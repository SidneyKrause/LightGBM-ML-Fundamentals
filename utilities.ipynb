{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a0e87bd24c1129",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551fe286",
   "metadata": {},
   "source": [
    "This notebook is used to outsource code. This serves two purposes. Firstly, the same code is made reusable in several other notebooks. In this way, the redundant listing of one and the same code is avoided. Secondly, sections of code can be outsourced that are only used once but would disrupt the flow of reading in the chapters. As a result, coherent storytelling can be guaranteed in the chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d71192e992e44",
   "metadata": {},
   "source": [
    "## 1. Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T10:31:54.741784Z",
     "start_time": "2024-09-29T10:31:49.361854Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import time\n",
    "import datetime as dt\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xg\n",
    "import optuna\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ec7c319303d9db",
   "metadata": {},
   "source": [
    "## 2. Helper Functions and Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5b7de",
   "metadata": {},
   "source": [
    "### 2.1 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f16e6363e5537198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_graph(graph: pd.DataFrame) -> None:\n",
    "    \"\"\"A helper function which plots a graph given an adjacency matrix\n",
    "\n",
    "    Args:\n",
    "        graph (pd.DataFrame): the adjacency matrix the graph is to be plotted for\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Replace NaN values with 0 to ensure all values are numeric\n",
    "    adj_matrix = graph.fillna(0)\n",
    "\n",
    "    # Initialize graph from the adjacency matrix\n",
    "    graph = nx.from_pandas_adjacency(adj_matrix)\n",
    "    pos = nx.circular_layout(graph)\n",
    "\n",
    "    # Draw the graph\n",
    "    nx.draw_networkx_edges(graph, pos)\n",
    "    nx.draw_networkx_nodes(graph, pos, node_size=700)\n",
    "    nx.draw_networkx_labels(graph, pos, font_size=12, font_family=\"sans-serif\")\n",
    "\n",
    "    # Add edge labels with weights\n",
    "    edge_labels = nx.get_edge_attributes(graph, \"weight\")\n",
    "    # Only include edges with weight > 0\n",
    "    edge_labels = {k: v for k, v in edge_labels.items() if v > 0}\n",
    "    nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.title(\"Weighted Graph from Adjacency Matrix\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def style_scatterplot(fig: go.Figure) -> None:\n",
    "    \"\"\"A helper function which styles plotly line charts in a uniform way\n",
    "\n",
    "    Args:\n",
    "        fig (go.Figure): the figure which needs to be styled\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=\"#FFF\",\n",
    "        title_x=0.5,\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        showline=True,\n",
    "        linewidth=1,\n",
    "        linecolor=\"black\",\n",
    "        showgrid=True,\n",
    "        gridcolor=\"lightgrey\",\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        showline=True,\n",
    "        linewidth=1,\n",
    "        linecolor=\"black\",\n",
    "        showgrid=True,\n",
    "        gridcolor=\"lightgrey\",\n",
    "    )\n",
    "\n",
    "\n",
    "def style_bar_chart(fig: go.Figure) -> None:\n",
    "    \"\"\"A helper function which styles plotly bar charts in a uniform way\n",
    "\n",
    "    Args:\n",
    "        fig (go.Figure): the figure which needs to be styled\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=\"#FFF\",\n",
    "        title_x=0.5,\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        showline=True,\n",
    "        linewidth=1,\n",
    "        linecolor=\"black\",\n",
    "        showgrid=False,\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        showline=True,\n",
    "        linewidth=1,\n",
    "        linecolor=\"black\",\n",
    "        showgrid=True,\n",
    "        gridcolor=\"lightgrey\",\n",
    "    )\n",
    "\n",
    "\n",
    "def add_crises(fig: go.Figure) -> None:\n",
    "    \"\"\"A helper function which adds major economic crises of the last 25 years as shaded areas to a chart\n",
    "\n",
    "    Args:\n",
    "        fig (go.Figure): the figure which needs to be styled\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Add shaded areas for major crises\n",
    "    fig_median_price_per_year.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=2000,\n",
    "        x1=2002,\n",
    "        y0=0,\n",
    "        y1=1,\n",
    "        line=dict(color=\"red\", width=0),\n",
    "        fillcolor=\"red\",\n",
    "        opacity=0.2,\n",
    "        xref=\"x\",\n",
    "        yref=\"paper\",\n",
    "    )\n",
    "    fig_median_price_per_year.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=2007,\n",
    "        x1=2009,\n",
    "        y0=0,\n",
    "        y1=1,\n",
    "        line=dict(color=\"red\", width=0),\n",
    "        fillcolor=\"red\",\n",
    "        opacity=0.2,\n",
    "        xref=\"x\",\n",
    "        yref=\"paper\",\n",
    "    )\n",
    "    fig_median_price_per_year.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=2020,\n",
    "        x1=2021,\n",
    "        y0=0,\n",
    "        y1=1,\n",
    "        line=dict(color=\"red\", width=0),\n",
    "        fillcolor=\"red\",\n",
    "        opacity=0.2,\n",
    "        xref=\"x\",\n",
    "        yref=\"paper\",\n",
    "    )\n",
    "\n",
    "    # Add annotations for the crises\n",
    "    fig_median_price_per_year.add_annotation(\n",
    "        x=2001,\n",
    "        y=1,\n",
    "        text=\"Dot-com Bubble\",\n",
    "        showarrow=False,\n",
    "        xref=\"x\",\n",
    "        yref=\"paper\",\n",
    "        font=dict(color=\"red\"),\n",
    "    )\n",
    "    fig_median_price_per_year.add_annotation(\n",
    "        x=2008,\n",
    "        y=1,\n",
    "        text=\"Global Financial Crisis\",\n",
    "        showarrow=False,\n",
    "        xref=\"x\",\n",
    "        yref=\"paper\",\n",
    "        font=dict(color=\"red\"),\n",
    "    )\n",
    "    fig_median_price_per_year.add_annotation(\n",
    "        x=2020,\n",
    "        y=1,\n",
    "        text=\"COVID-19 Pandemic\",\n",
    "        showarrow=False,\n",
    "        xref=\"x\",\n",
    "        yref=\"paper\",\n",
    "        font=dict(color=\"red\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def update_interactive_chart(button: widgets.widget_button.Button) -> None:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        button (widgets.widget_button.Button): button enabling submission\n",
    "    \"\"\"\n",
    "    # Get dropwdown values\n",
    "    clear_output(wait=True)\n",
    "    display(controls)\n",
    "    x_axis = x_dropdown.value\n",
    "    y_axis = y_dropdown.value\n",
    "\n",
    "    # Style and display chart\n",
    "    fig = px.scatter(df_cars, x=x_axis, y=y_axis)\n",
    "    style_scatterplot(fig)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ab1bf",
   "metadata": {},
   "source": [
    "### 2.2 Optuna Optimization Objective Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ede0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_dt(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"Function whose output needs to be minimized by adapting the hyperparameters. It suggests hyperparameter intervals and trains a decision tree regressor using chosen hyperparameters.\n",
    "    The model is then applied to predict on the test set. The predictions are used to calculate the RMSE error metric and return its value.\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.trial.Trial): Trial object which suggests hyperparameter values and manages optimization\n",
    "\n",
    "    Returns:\n",
    "        rmse (float): value of the error metric which needs to be minimized\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"criterion\": \"squared_error\",\n",
    "        \"splitter\": \"best\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 30, 50),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "        \"min_weight_fraction_leaf\": trial.suggest_float(\n",
    "            \"min_weight_fraction_leaf\", 0.0, 0.5\n",
    "        ),\n",
    "        \"max_features\": trial.suggest_int(\"max_features\", 5, 12),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "    # Instantiate and train Decision Tree Regressor\n",
    "    dt_regressor = DecisionTreeRegressor(**params)\n",
    "    dt_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on test set and return RMSE\n",
    "    y_pred = dt_regressor.predict(X_test)\n",
    "    rmse = metrics.root_mean_squared_error(y_test, y_pred)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def objective_xgb(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"Function whose output needs to be minimized by adapting the hyperparameters. It suggests hyperparameter intervals and trains a XGBoost regressor using chosen hyperparameters.\n",
    "    The model is then applied to predict on the test set. The predictions are used to calculate the RMSE error metric and return its value.\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.trial.Trial): Trial object which suggests hyperparameter values and manages optimization\n",
    "\n",
    "    Returns:\n",
    "        rmse (float): value of the error metric which needs to be minimized\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"eta\": trial.suggest_float(\"eta\", 0.0, 0.2),\n",
    "        \"gamma\": trial.suggest_int(\"gamma\", 30, 50),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 14, 20),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 0, 10),\n",
    "        \"max_delta_step\": trial.suggest_int(\"max_delta_step\", 0, 1),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 1e-3, 1.0, log=True),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0, log=True),\n",
    "        \"lambda\": trial.suggest_int(\"lambda\", 1, 10),\n",
    "        \"alpha\": trial.suggest_int(\"alpha\", 0, 10),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "    }\n",
    "\n",
    "    # Instantiate and train XGBoost Regressor\n",
    "    xgb_regressor = xg.XGBRegressor(**params)\n",
    "    xgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on test set and return RMSE\n",
    "    y_pred = xgb_regressor.predict(X_test)\n",
    "    rmse = metrics.root_mean_squared_error(y_test, y_pred)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def objective_lgb(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"Function whose output needs to be minimized by adapting the hyperparameters. It suggests hyperparameter intervals and trains a LightGBM regressor using chosen hyperparameters.\n",
    "    The model is then applied to predict on the test set. The predictions are used to calculate the RMSE error metric and return its value.\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.trial.Trial): Trial object which suggests hyperparameter values and manages optimization\n",
    "\n",
    "    Returns:\n",
    "        rmse (float): value of the error metric which needs to be minimized\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"num_iterations\": trial.suggest_int(\"num_iterations\", 50, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.05, 1.0, log=True\n",
    "        ),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 20),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.05, 1.0, log=True\n",
    "        ),\n",
    "        \"metric\": \"rmse\",\n",
    "    }\n",
    "\n",
    "    # Instantiate and train LightGBM Regressor\n",
    "    lgb_regressor = lgb.train(\n",
    "        params=params,\n",
    "        train_set=train_set,\n",
    "    )\n",
    "\n",
    "    # Predict on test set and return RMSE\n",
    "    y_pred = lgb_regressor.predict(X_test)\n",
    "    rmse = metrics.root_mean_squared_error(y_test, y_pred)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a78b7",
   "metadata": {},
   "source": [
    "### 2.3 Benchmarking Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ffe194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded (default and optimized) hyperparameters for training a LightGBM Regressor\n",
    "params_lgb = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"num_iterations\": 100,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_leaves\": 31,\n",
    "    \"min_data_in_leaf\": 20,\n",
    "    \"bagging_fraction\": 1.0,\n",
    "    \"bagging_freq\": 0,\n",
    "    \"feature_fraction\": 1.0,\n",
    "    \"metric\": \"rmse\",\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "params_lgb_opt = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"num_iterations\": 376,\n",
    "    \"learning_rate\": 0.02037086620821208,\n",
    "    \"num_leaves\": 527,\n",
    "    \"min_data_in_leaf\": 72,\n",
    "    \"bagging_fraction\": 0.9944312804038378,\n",
    "    \"bagging_freq\": 16,\n",
    "    \"feature_fraction\": 0.5204062794631757,\n",
    "    \"metric\": \"rmse\",\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "\n",
    "def track_training_time(model_name: str, optimized: bool) -> float:\n",
    "    \"\"\"Tracks the training time of one of the three benchmarking models (Decision Tree Regressor, XGBoost Regressor, LightGBM Regressor)\n",
    "\n",
    "    Args:\n",
    "        model_name (str): the name of the model the training time should be tracked for\n",
    "        optimized (bool): states whether the hyperparameters of the model have prviously been optimized\n",
    "\n",
    "    Returns:\n",
    "        float: the training time of the stated model\n",
    "    \"\"\"\n",
    "    if model_name == \"dt_regressor\":\n",
    "        # Instantiate Decision Tree Regressor\n",
    "        if not optimized:\n",
    "            regressor = DecisionTreeRegressor(**params_dt)\n",
    "        else:\n",
    "            regressor = DecisionTreeRegressor(**params_dt_opt)\n",
    "\n",
    "    elif model_name == \"xgb_regressor\":\n",
    "        # Instantiate XGBoost Regressor\n",
    "        if not optimized:\n",
    "            regressor = xg.XGBRegressor(**params_xgb)\n",
    "        else:\n",
    "            regressor = xg.XGBRegressor(**params_xgb_opt)\n",
    "\n",
    "    else:\n",
    "        # Instantiate and train LightGBM Regressor, track the process time\n",
    "        if not optimized:\n",
    "            training_start = time.process_time()\n",
    "            lgb.train(params=params_lgb, train_set=train_set_lgb)\n",
    "            training_end = time.process_time()\n",
    "        else:\n",
    "            training_start = time.process_time()\n",
    "            lgb.train(params=params_lgb_opt, train_set=train_set_lgb)\n",
    "            training_end = time.process_time()\n",
    "\n",
    "        # Return the training time\n",
    "        return training_end - training_start\n",
    "\n",
    "    # Fit Decision Tree Regressor or XGBoost Regressor using the training data and track the process time\n",
    "    training_start = time.process_time()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    training_end = time.process_time()\n",
    "\n",
    "    # Return the training time\n",
    "    return training_end - training_start\n",
    "\n",
    "\n",
    "def normalize_importance(values: np.ndarray | dict) -> np.ndarray:\n",
    "    \"\"\"Normalizes feature importance values by converting absolute to relative values. This allows us to compare diffently scaled importances of different models.\n",
    "\n",
    "    Args:\n",
    "        values (np.ndarray | dict): feature importance values\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: normalized feature importance values\n",
    "    \"\"\"\n",
    "    if isinstance(values, np.ndarray):\n",
    "        return values / np.sum(values)\n",
    "    elif isinstance(values, dict):\n",
    "        values_array = np.array(list(values.values()))\n",
    "        return values_array / np.sum(values_array)\n",
    "\n",
    "\n",
    "def track_feature_importance(model_name: str, optimized: bool) -> np.ndarray:\n",
    "    \"\"\"Tracks the feature importance of one of the three benchmarking models (Decision Tree Regressor, XGBoost Regressor, LightGBM Regressor)\n",
    "\n",
    "    Args:\n",
    "        model_name (str): the name of the model the training time should be tracked for\n",
    "        optimized (bool): states whether the hyperparameters of the model have previously been optimized\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: the feature importance of the stated model\n",
    "    \"\"\"\n",
    "    if model_name == \"dt_regressor\":\n",
    "        # Instantiate Decision Tree Regressor\n",
    "        if not optimized:\n",
    "            regressor = DecisionTreeRegressor(**params_dt)\n",
    "        else:\n",
    "            regressor = DecisionTreeRegressor(**params_dt_opt)\n",
    "\n",
    "        # Fit XGBoost Regressor using the training data and track RMSE evaluation on train and test set per iteration\n",
    "        regressor.fit(X_train, y_train)\n",
    "\n",
    "        feature_importance = regressor.feature_importances_\n",
    "\n",
    "    elif model_name == \"xgb_regressor\":\n",
    "        # Instantiate XGBoost Regressor\n",
    "        if not optimized:\n",
    "            regressor = xg.XGBRegressor(**params_xgb)\n",
    "        else:\n",
    "            regressor = xg.XGBRegressor(**params_xgb_opt)\n",
    "\n",
    "        # Fit XGBoost Regressor using the training data and track RMSE evaluation on train and test set per iteration\n",
    "        regressor.fit(X_train, y_train)\n",
    "\n",
    "        # Store feature importance, skip 0 values\n",
    "        feature_importance = regressor.get_booster().get_score(importance_type=\"gain\")\n",
    "        feature_importance = {\n",
    "            feature: feature_importance.get(feature, 0) for feature in X_train.columns\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        eval_result = {}\n",
    "        # Train LightGBM Regressor and track RMSE evaluation on train and test set per iteration\n",
    "        if not optimized:\n",
    "            regressor = lgb.train(\n",
    "                params=params_lgb,\n",
    "                train_set=train_set_lgb,\n",
    "                valid_sets=[train_set_lgb, test_set_lgb],\n",
    "                callbacks=[lgb.record_evaluation(eval_result)],\n",
    "            )\n",
    "        else:\n",
    "            regressor = lgb.train(\n",
    "                params=params_lgb_opt,\n",
    "                train_set=train_set_lgb,\n",
    "                valid_sets=[train_set_lgb, test_set_lgb],\n",
    "                callbacks=[lgb.record_evaluation(eval_result)],\n",
    "            )\n",
    "\n",
    "        feature_importance = regressor.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "    return normalize_importance(feature_importance)\n",
    "\n",
    "\n",
    "def track_learning_curve(\n",
    "    model_name: str, optimized: bool\n",
    ") -> tuple[list[float], list[float]]:\n",
    "    \"\"\"Tracks the training time of one of the three benchmarking models (Decision Tree Regressor, XGBoost Regressor, LightGBM Regressor)\n",
    "\n",
    "    Args:\n",
    "        model_name (str): the name of the model the training time should be tracked for\n",
    "        optimized (bool): states whether the hyperparameters of the model have prviously been optimized\n",
    "\n",
    "    Returns:\n",
    "        training_delta (float): the training time of the stated model\n",
    "    \"\"\"\n",
    "    if model_name == \"xgb_regressor\":\n",
    "        # Instantiate XGBoost Regressor\n",
    "        if not optimized:\n",
    "            regressor = xg.XGBRegressor(**params_xgb)\n",
    "        else:\n",
    "            regressor = xg.XGBRegressor(**params_xgb_opt)\n",
    "\n",
    "        # Fit XGBoost Regressor using the training data and track RMSE evaluation on train and test set per iteration\n",
    "        regressor.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        eval_values = regressor.evals_result()\n",
    "\n",
    "    else:\n",
    "        eval_values = {}\n",
    "        # Train LightGBM Regressor and track RMSE evaluation on train and test set per iteration\n",
    "        if not optimized:\n",
    "            regressor = lgb.train(\n",
    "                params=params_lgb,\n",
    "                train_set=train_set_lgb,\n",
    "                valid_sets=[train_set_lgb, test_set_lgb],\n",
    "                callbacks=[lgb.record_evaluation(eval_values)],\n",
    "            )\n",
    "        else:\n",
    "            regressor = lgb.train(\n",
    "                params=params_lgb_opt,\n",
    "                train_set=train_set_lgb,\n",
    "                valid_sets=[train_set_lgb, test_set_lgb],\n",
    "                callbacks=[lgb.record_evaluation(eval_values)],\n",
    "            )\n",
    "\n",
    "    return standardize_evaluation(eval_values)\n",
    "\n",
    "\n",
    "def standardize_evaluation(eval_values):\n",
    "    evaluation_keys = list(eval_values.keys())\n",
    "\n",
    "    return eval_values[evaluation_keys[0]][\"rmse\"], eval_values[evaluation_keys[1]][\n",
    "        \"rmse\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc83f296",
   "metadata": {},
   "source": [
    "### 2.4 Custom LightGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc0e0483130ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarPriceRegressor:\n",
    "    \"\"\"Class to perform car price regression with custom user inputs\n",
    "\n",
    "    Attributes:\n",
    "        df_cars (pd.DataFrame): captures the whole cars data\n",
    "        custom_data (dict): contains the values entered by the user\n",
    "        custom_df (pd.DataFrame): contains the values entered by the user in the final format\n",
    "        model_dropdown (widgets.widget_selection.Dropdown): contains the car models related to the selected car brand\n",
    "        opt_bst (lgb.basic.Booster): trained LightGBM model\n",
    "        label_encoders (dict): label encoders used for model training\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lgb_regressor: lgb.basic.Booster, label_encoders: dict) -> None:\n",
    "        \"\"\"Initialize instance attributes\n",
    "\n",
    "        Args:\n",
    "            lgb_regressor (lgb.basic.Booster): trained LightGBM model\n",
    "            label_encoders (dict): label encoders used for model training\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.df_cars = pd.read_csv(\"data/cars_cleaned.csv\")\n",
    "        self.custom_data = None\n",
    "        self.custom_df = None\n",
    "        self.model_dropdown = None\n",
    "        self.lgb_regressor = lgb_regressor\n",
    "        self.label_encoders = label_encoders\n",
    "\n",
    "    def update_model_options(\n",
    "        self, change: dict, submit_button: widgets.widget_button.Button\n",
    "    ) -> None:\n",
    "        \"\"\"Dynamically updates model options based on the selected brand\n",
    "\n",
    "        Args:\n",
    "            change (dict): contains current and previous states of dropdowns\n",
    "            submit_button (widgets.widget_button.Button): button enabling submission\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "            selected_brand = change[\"new\"]\n",
    "            self.custom_data[\"brand\"] = selected_brand\n",
    "\n",
    "            # Filter models based on the selected brand\n",
    "            filtered_models = self.df_cars[self.df_cars[\"brand\"] == selected_brand][\n",
    "                \"model\"\n",
    "            ].unique()\n",
    "\n",
    "            # Update the options of the model dropdown\n",
    "            self.model_dropdown.options = filtered_models\n",
    "            self.model_dropdown.value = None\n",
    "\n",
    "            # Check if form is ready to submit\n",
    "            self.check_submit_ready(submit_button)\n",
    "\n",
    "    def on_change(\n",
    "        self,\n",
    "        change: dict,\n",
    "        feature_name: list[str],\n",
    "        submit_button: widgets.widget_button.Button,\n",
    "    ) -> None:\n",
    "        \"\"\"Update custom data based on dropdown and slider selection\n",
    "\n",
    "        Args:\n",
    "            change (dict): contains current and previous states of dropdowns and sliders\n",
    "            feature_name (list[str]): contains either the categorical or the numerical features of df_cars as strings\n",
    "            submit_button (widgets.widget_button.Button): button enabling submission\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "            self.custom_data[feature_name] = change[\"new\"]\n",
    "\n",
    "            # Check if form is ready to submit\n",
    "            self.check_submit_ready(submit_button)\n",
    "\n",
    "    def check_submit_ready(self, submit_button: widgets.widget_button.Button) -> None:\n",
    "        \"\"\"Checks the state of dropdwons and sliders before allowing custom data to be submitted\n",
    "\n",
    "        Args:\n",
    "            submit_button (widgets.widget_button.Button): button enabling submission\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        submit_button.disabled = not all(\n",
    "            value is not None for value in self.custom_data.values()\n",
    "        )\n",
    "\n",
    "    def on_submit(self, b: widgets.widget_button.Button) -> None:\n",
    "        \"\"\"Displays the user input and returns the predicted car price\n",
    "\n",
    "        Args:\n",
    "            b (widgets.widget_button.Button): button enabling submission\n",
    "        \"\"\"\n",
    "        # Create a DataFrame from the custom_data dictionary\n",
    "        self.custom_df = pd.DataFrame([self.custom_data])\n",
    "        self.custom_df = self.custom_df[\n",
    "            self.df_cars.drop(\"price_in_euro\", axis=1).columns\n",
    "        ]\n",
    "\n",
    "        # Display the custom DataFrame\n",
    "        print(\"User input data:\")\n",
    "        display(self.custom_df)\n",
    "\n",
    "        # Call method to encode the custom data and return predicted price\n",
    "        predicted_price = self.encode_and_predict()\n",
    "        print(f\"Predicted car price: {predicted_price}\")\n",
    "\n",
    "    def display_input_widgets(\n",
    "        self,\n",
    "        cat_features: list[str],\n",
    "        num_features: list[str],\n",
    "        submit_button: widgets.widget_button.Button,\n",
    "    ):\n",
    "        \"\"\"Displays dropdowns and sliders, captures selections\n",
    "\n",
    "        Args:\n",
    "            cat_features (list[str]): contains the categorical features of df_cars as strings\n",
    "            num_features (list[str]): contains the numerical features of df_cars as strings\n",
    "            submit_button (widgets.widget_button.Button): button enabling submission\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Initialize custom_data with None values\n",
    "        self.custom_data = dict.fromkeys(cat_features + num_features)\n",
    "\n",
    "        # Initialize empty list for input widgets\n",
    "        input_widgets = []\n",
    "\n",
    "        # Display brand dropdown\n",
    "        brand_dropdown = widgets.Dropdown(\n",
    "            options=self.df_cars[\"brand\"].unique(),\n",
    "            value=None,\n",
    "            description=f\"Brand of your car:\",\n",
    "            style={\"description_width\": \"initial\"},\n",
    "            layout=widgets.Layout(width=\"initial\"),\n",
    "        )\n",
    "        # Display model dropdown\n",
    "        self.model_dropdown = widgets.Dropdown(\n",
    "            options=[],\n",
    "            value=None,\n",
    "            description=f\"Model of your car:\",\n",
    "            style={\"description_width\": \"initial\"},\n",
    "            layout=widgets.Layout(width=\"initial\"),\n",
    "        )\n",
    "        # Observe changes in the brand dropdown and update model options\n",
    "        brand_dropdown.observe(\n",
    "            lambda change: self.update_model_options(change, submit_button),\n",
    "            names=\"value\",\n",
    "        )\n",
    "        # Add brand dropdown to input widgets\n",
    "        input_widgets.append(brand_dropdown)\n",
    "        # Observe changes in the model dropdown and update custom_data\n",
    "        self.model_dropdown.observe(\n",
    "            lambda change, col=\"model\": self.on_change(change, col, submit_button),\n",
    "            names=\"value\",\n",
    "        )\n",
    "        # Add model dropdown to input widgets\n",
    "        input_widgets.append(self.model_dropdown)\n",
    "\n",
    "        # Display dropdowns for categorical features (except brand and model)\n",
    "        for cat_feature in [i for i in cat_features if i not in [\"model\", \"brand\"]]:\n",
    "            dropdown = widgets.Dropdown(\n",
    "                options=self.df_cars[cat_feature].unique(),\n",
    "                value=None,\n",
    "                description=f\"{cat_feature.capitalize().replace('_', ' ')} of your car:\",\n",
    "                style={\"description_width\": \"initial\"},\n",
    "                layout=widgets.Layout(width=\"initial\"),\n",
    "            )\n",
    "            # Observe changes in the dropdown selection and update custom_data\n",
    "            dropdown.observe(\n",
    "                lambda change, col=cat_feature: self.on_change(\n",
    "                    change, col, submit_button\n",
    "                ),\n",
    "                names=\"value\",\n",
    "            )\n",
    "            # Add dropdown to input widgets\n",
    "            input_widgets.append(dropdown)\n",
    "\n",
    "        # Display sliders for numerical features, distinguishing between discrete and continous ones\n",
    "        for num_feature in num_features:\n",
    "            if num_feature in [\n",
    "                \"year\",\n",
    "                \"power_ps\",\n",
    "                \"power_kw\",\n",
    "                \"mileage_in_km\",\n",
    "                \"registration_month\",\n",
    "            ]:\n",
    "                slider = widgets.IntSlider(\n",
    "                    value=int(self.df_cars[num_feature].mean()),\n",
    "                    min=self.df_cars[num_feature].min(),\n",
    "                    max=self.df_cars[num_feature].max(),\n",
    "                    step=1,\n",
    "                    description=f\"{num_feature.capitalize().replace('_', ' ')} of your car:\",\n",
    "                    style={\"description_width\": \"initial\"},\n",
    "                    layout=widgets.Layout(width=\"initial\"),\n",
    "                )\n",
    "            else:\n",
    "                slider = widgets.FloatSlider(\n",
    "                    value=self.df_cars[num_feature].mean(),\n",
    "                    min=self.df_cars[num_feature].min(),\n",
    "                    max=self.df_cars[num_feature].max(),\n",
    "                    step=0.1,\n",
    "                    description=f\"{num_feature.capitalize().replace('_', ' ')} of your car:\",\n",
    "                    style={\"description_width\": \"initial\"},\n",
    "                    layout=widgets.Layout(width=\"initial\"),\n",
    "                )\n",
    "            # Observe changes in the slider and update custom_data\n",
    "            slider.observe(\n",
    "                lambda change, col=num_feature: self.on_change(\n",
    "                    change, col, submit_button\n",
    "                ),\n",
    "                names=\"value\",\n",
    "            )\n",
    "            # Add slider to input widgets\n",
    "            input_widgets.append(slider)\n",
    "\n",
    "        # Display all input widgets vertically aligned\n",
    "        for input_widget in input_widgets:\n",
    "            display(input_widget)\n",
    "\n",
    "    def encode_and_predict(self):\n",
    "        \"\"\"Encodes categorical features and performs a regression using the trained LightGBM model\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Encode categorical features with the same labels as for training\n",
    "        self.custom_df[list(self.label_encoders.keys())] = self.custom_df[\n",
    "            list(self.label_encoders.keys())\n",
    "        ].apply(lambda x: self.label_encoders[x.name].transform(x))\n",
    "\n",
    "        # Perform prediction using the trained LightGBM model\n",
    "        prediction = self.lgb_regressor.predict(self.custom_df)\n",
    "        return prediction[0]\n",
    "\n",
    "    def predict_car_price(\n",
    "        self, cat_features: list[str], num_features: list[str]\n",
    "    ) -> None:\n",
    "        \"\"\"Main function, creates custom data from user inputs and implements submission logic\n",
    "\n",
    "        Args:\n",
    "            cat_features (list[str]): contains the categorical features of df_cars as strings\n",
    "            num_features (list[str]): contains the numerical features of df_cars as strings\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Define the submit button\n",
    "        submit_button = widgets.Button(description=\"Calculate\", disabled=True)\n",
    "\n",
    "        # Display input widgets (dropdowns and sliders)\n",
    "        self.display_input_widgets(cat_features, num_features, submit_button)\n",
    "\n",
    "        # Define the click event of the submit button and display the latter\n",
    "        submit_button.on_click(self.on_submit)\n",
    "        display(submit_button)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightgbm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
