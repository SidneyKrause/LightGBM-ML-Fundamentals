{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26e686a1-bf47-4cc2-ab73-bafaf5f7deec",
   "metadata": {},
   "source": [
    "# Theoretical Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e9c2f-8c5b-40d4-b9d2-2bc1d28b5bce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27dc8c0-d0b6-4f86-816e-d527a27881e1",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is part of a project conducted within the course \"Applied Machine Learning Fundamentals\" at the Duale Hochschule Baden-Württemberg Heilbronn. The project's objective is to provide students with a practical understanding of machine learning model construction and evaluation. The objective is to convey theoretical knowledge and competences in machine learning by selecting one of several models and providing an explanation of its functionality, along with a demonstration of its application using a self-selected data set. Our team, including Lukas Beißwenger, Sidney Krause, Jan Lau, and Marius Lüdtke, has chosen to take over the topic of \"Boosting: LightGBM\". Before diving into LightGBM, we will first introduce important underlying principles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b801a719-eb4d-4f9e-a947-d2e2de49eea3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ecd9cd-4c84-4c77-af19-785c8a4626f8",
   "metadata": {},
   "source": [
    "As stated by Xu et al. (2005, p. 323), a decision \"tree is composed of a root node (containing all data), a set of internal nodes (splits) and a set of terminal nodes (leaves).\" The nodes may be either binary (two-way) or multiway, involving multiple branches. Furthermore, Xu et al. (2005, p. 323) state that the conventional decision tree employs a top-down methodology, whereby a complex decision is decomposed into a sequence of progressively simpler, more comprehensible decisions, ultimately leading to an interpretable solution.\n",
    "\n",
    "The fundamental concept is illustrated in Figure 1, which is adapted from De Ville (2013, p. 449) and serves to demonstrate the survival of the Titanic catastrophe. The figure depicts a prototypical decision tree. The structure of the decision tree is generated through a step-by-step, recursive process that partitions the target variable based on key discriminating features of one or more related input variables. In this context, the root node represents the 1,309 passengers on the Titanic. The Boolean target variable in the root node serves to distinguish between two possible outcomes: survival and non-survival of the participants. In general, as De Ville (2013, p. 449) notes, the process of constructing a decision tree automatically accommodates all levels of measurement, including nominal, ordinal, and interval, whether in the target or input positions. For example, if a scalar level of the nominal scale is employed, as illustrated in the aforementioned example, the resulting decision tree may be classified as a classification tree. As De Ville (2013, p. 451) notes, for ordinal or interval measures, partitioned values are grouped in a manner that optimizes discrimination between high and low percentages in the target field within descendent nodes.\n",
    "\n",
    "In the initial stage, the leaves symbolize the male and female passengers. As previously stated by De Ville (2013, p. 450), the term \"leaf\" is frequently utilized when employing the tree metaphor in this context. Nevertheless, the more general term \"node\" is preferred, in recognition of the fact that decision trees constitute a specific type of connected graph. In graph theory, the partitions are referred to as edges, and the leaves are considered nodes. By maintaining the tree metaphor, each subsequent partitioning results in a visual representation that resembles a tree, with a root node at the top and branching descendant nodes. However, trees may also develop asymmetrically, with descendant nodes exhibiting disparate subpartitions (cf. De Ville, 2013, p. 451).\n",
    "\n",
    "In this illustrative example, the survival rate for females was 72.7%, while the survival rate for males was 19.1%. In most cases, the input that creates the most significant separation in variability among the descendant nodes is selected. This is exemplified by the choice of gender in the first partitioning. In practice, analysts frequently exercise control over the sequence in which branch partitions are unfolded, with the aim of providing a more comprehensive explanation of a series of effects or validating the conditional relationships believed to exist between various inputs and the resulting nodes they generate. In this manner, descendant nodes may serve to illustrate localized effects, which are contingent upon the sequence of input variables that constitute the partitions. Such localized effects, which emerge from interactions among the input variables, are frequently designated as \"interaction effects.\" The automatic handling of different measurement levels, in conjunction with the tree's visual representation, enhances the model's flexibility, ease of use, and clarity of interpretation. Moreover, although not depicted in the figure, the model can be modified to either include or exclude missing values, thereby enhancing its flexibility and usability (cf. De Ville, 2013, p. 451)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e52fa-fd64-4975-b1a1-559683aad335",
   "metadata": {},
   "source": [
    "![Figure 1.png](images/figure_1.png)\n",
    "\n",
    "Figure 1: An exemplary decision tree on the survivors of the Titanic sinking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84d056-71d4-4b0f-9585-d11983373ada",
   "metadata": {},
   "source": [
    "Figure 2, derived from Beauleac and Rosenthal (2019, p. 1053), illustrates a set of attributes pertaining to a data item within the context of instance space. As defined by Smith-Miles (2012, p. 1), the instance space is understood as a high-dimensional space that summarizes a set of instances by a feature vector. A decision tree partitions the instance space at each internal node into at least two subspaces. In order to achieve this, the input attribute values of a data item are passed to a discrete function in each internal node (cf. Rokach 2005, p. 165). The function defines the outgoing edge and, consequently, the path to the subsequent internal node or leaf. In accordance with the observations presented by Suthaharan (2016, p. 165), if the predicted responses are continuous (i.e., capable of assuming any real number), the decision tree is designated as a regression tree. Conversely, if the predicted responses are categorical (i.e., belonging to distinct classes), the tree is designated a classification tree. In the context of our use case, the regression tree is of greater significance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59fbf99-e432-418d-bcd3-c85f03605819",
   "metadata": {
    "tags": []
   },
   "source": [
    "![image.png](images/figure_2.png)\n",
    "\n",
    "Figure 2: Representation of a decision tree that partitions the instance space based on two attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae050b99-4237-41b9-b5a8-c02dfd810fc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c07e034-63e1-431e-b25b-725763bedc31",
   "metadata": {
    "tags": []
   },
   "source": [
    "As explained by Dong (2020, p. 241), the ensemble learning methodology employs a combination of multiple machine learning algorithms with the objective of deriving weak predictions by extracting features from heterogenous data projections. Subsequently, the predictions are integrated through a variety of voting mechanisms, thereby resulting in enhanced performance when compared to the output of a single algorithm. This single algorithm would typically be a part of the traditional machine learning approaches, where only a single strong model is trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e718ac65-53ab-4bf5-b497-d032859b7b03",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71150f7e-7391-4c5f-8ccd-71b7834e9185",
   "metadata": {
    "tags": []
   },
   "source": [
    "The boosting approach represents a concrete form of the aforementioned ensemble learning. The boosting approach entails the sequential incorporation of new weak learners into the ensemble. The weak learner, which is incorporated into the ensemble at each iteration, is trained on the basis of the error of the ensemble that has been trained so far. As mentioned by Mayr et al. (2014, p. 3), the enhancement of accuracy is achieved through the implementation of a more robust focus on challenging observations. The final prediction is derived by incorporating all weak learners into a unified model. The weight assigned to each weak learner's prediction is based on their performance during training, with higher-performing learners receiving a higher weighting. The final prediction is determined by a weighted majority vote, with the class most frequently predicted by the weak learners, taking into account their respective weights, becoming the output of the boosting algorithm.\n",
    "\n",
    "The concept of Gradient Boosting was initially proposed by Friedman (2001, n.p.). This is derived from the foundation of boosting algorithms, as proposed by Freund/Schapire (1996, n.p.), particularly AdaBoost. The primary distinction between AdaBoost and gradient boosting is in the manner of training the models. In contrast to AdaBoost, Gradient Boosting employs a direct optimization of residuals through gradient descent to minimize the loss function, which could be the mean squared error in regression, while simultaneously adjusting the weights of misclassified instances. This results in the generation of an algorithm that reduces the error rate of the model.\n",
    "\n",
    "However, boosting methods are also at risk of overfitting, which occurs when models become overly calibrated to the training data set and are unable to generalize to unseen data. Overfitting frequently results in suboptimal performance on test datasets, as the model not only captures the underlying patterns but also incorporates noise and irrelevant fluctuations present in the training data. One key indicator of overfitting is the presence of large estimates of model parameters, where the model becomes overly complex, adjusting to minute variations that do not translate well to new examples.\n",
    "\n",
    "In the following, we aim to inttroduce the mathematical formulation for gradient boosting. For the sake of argument, let us assume that we are provided with a training dataset, represented by the set of tuples  ${(x_i, y_i)}_{i=1}^{n}$, where $x_i \\in \\mathbb{R}^d$ denotes the input features, and $y_i \\in \\mathbb{R}$ refers to the corresponding target for a regression task. The objective is to identify a function, $F(x)$, that approximates the true relationship between $x$ and $y$. In other words, the objective is to find a function $F(x)$ that minimizes a loss function $L(y, F(x))$ over the dataset, where $L(y, F(x))$ measures the discrepancy between the predicted and true values.\n",
    "\n",
    "The boosting process functions by means of an incremental enhancement of the function $F(x)$ through the application of a series of weak learners, frequently in the form of decision trees. This would be a return to the initial chapter. \n",
    "\n",
    "The process has its origin in the initialization of the model with a constant function, the objective of which is the minimization of the loss function across all data points.\n",
    "\n",
    "$$ F_0(x) = \\arg \\min_{\\gamma} \\sum_{i=1}^{n} L(y_i, \\gamma) $$\n",
    "\n",
    "In the context of regression tasks with a squared error loss, as illustrated in our example, the mean of the target values, $y$, is typically the optimal solution.\n",
    "\n",
    "$$ F_0(x) = \\frac{1}{n} \\sum_{i=1}^{n} y_i $$\n",
    "\n",
    "Subsequently, the gradient boosting algorithm builds the model in stages, refining the approximation $F(x)$ at each step $m$. At each step, a new weak learner $h_m(x)$ is added to correct the errors of the current model $F_{m-1}(x)$. The new model is updated as follows:\n",
    "\n",
    "$$ F_m(x) = F_{m-1}(x) + \\nu h_m(x) $$\n",
    "\n",
    "where $\\nu$ is the learning rate, a small constant that controls the contribution of each weak learner.\n",
    "\n",
    "To determine $h_m(x)$, we use gradient descent on the loss function. The residuals, or errors from the previous iteration, are the negative gradient of the loss function with respect to the current predictions:\n",
    "\n",
    "$$ r_{im} = - \\left[ \\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)} \\right] \\Bigg|{F(x) = F_{m-1}(x)} $$\n",
    "\n",
    "For the squared error loss, $L(y, F(x)) = (y - F(x))^2$, the residuals are simply:\n",
    "\n",
    "$$ r_{im} = y_i - F_{m-1}(x_i) $$\n",
    "\n",
    "Next, the weak learner $h_m(x)$ is trained to fit the residuals by minimizing the following:\n",
    "\n",
    "$$ h_m(x) = \\arg \\min_h \\sum_{i=1}^{n} \\left( r_{im} - h(x_i) \\right)^2 $$\n",
    "\n",
    "Finally, the model is updated:\n",
    "\n",
    "$$ F_m(x) = F_{m-1}(x) + \\nu h_m(x) $$\n",
    "\n",
    "This process is repeated for $M$ iterations, yielding the final model:\n",
    "\n",
    "$$ F_M(x) = F_0(x) + \\sum_{m=1}^{M} \\nu h_m(x) $$\n",
    "\n",
    "The learning rate $\\nu \\in (0, 1)$ is a hyperparameter that controls the step size of each update. A smaller value of $\\nu$ requires more iterations but can lead to a more accurate and robust model. The algorithm stops when the improvement in the loss function becomes negligible or after a predetermined number of iterations.\n",
    "\n",
    "Gradient Boosting can be applied to a variety of loss functions, including the squared error loss for regression, the logistic loss for classification, and more complex loss functions for different tasks. The principal advantage of this method is its flexibility with regard to tasks such as classification, regression, and others. LightGBM builds upon this topic, which will be explained in the following chapters.\n",
    "\n",
    "(cf. Freund/Schapire 1996, n.p.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1b857",
   "metadata": {},
   "source": [
    "1.1_theoretical_foundation | [>>>](1.2_introducing_LightGBM.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightgbm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
